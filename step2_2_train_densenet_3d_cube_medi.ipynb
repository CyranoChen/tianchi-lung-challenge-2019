{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys; print('Python %s on %s' % (sys.version, sys.platform))\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob, iglob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np; print('numpy', np.__version__)\n",
    "import cv2; print('opencv', cv2.__version__)\n",
    "import sklearn; print('sklearn', sklearn.__version__)\n",
    "import tensorflow as tf; print('tensorflow', tf.__version__)\n",
    "import tensorflow.keras as keras; print('keras', keras.__version__)\n",
    "\n",
    "import settings\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.extend(['./models'])\n",
    "print('sys.path', sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpu visible environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "# gpu allow_growth\n",
    "config.gpu_options.allow_growth = True\n",
    "keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'densenet3d'\n",
    "wtype = 'medi'\n",
    "dataset_name = 'cube_' + wtype\n",
    "unique_id = int(time.time())\n",
    "\n",
    "img_slice, img_rows, img_cols, channels = 32, 32, 32, 1\n",
    "num_classes = 3\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.se_densenet_3d import SEDenseNet\n",
    "\n",
    "model = SEDenseNet(input_shape=(img_slice, img_rows, img_cols, channels),\n",
    "                        depth=52,\n",
    "                        nb_dense_block=4,\n",
    "                        growth_rate=12,\n",
    "                        nb_filter=-1,\n",
    "                        nb_layers_per_block=-1,\n",
    "                        bottleneck=True,\n",
    "                        reduction=0.5,\n",
    "                        dropout_rate=0.2,\n",
    "                        weight_decay=1e-4,\n",
    "                        subsample_initial_block=True,\n",
    "                        maxpool_initial_block=False,\n",
    "                        include_top=True,\n",
    "                        weights=None,\n",
    "                        input_tensor=None,\n",
    "                        classes=num_classes,\n",
    "                        activation='softmax')\n",
    "\n",
    "model.summary()\n",
    "                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_name, len([l.name for l in model.layers if ('conv' in str(type(l)) or 'dense' in str(type(l)))])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(f'./output/{model_name}/1564138383/' + \"model-best.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from generator import get_classify_file_list, split_dataset, ClassifySequence\n",
    "dataset = get_classify_file_list(wtype=wtype)\n",
    "\n",
    "trainset, validset, _ = split_dataset(dataset, train_by_valid=0.02)\n",
    "\n",
    "gen_train = ClassifySequence(trainset, wtype=wtype, batch_size=batch_size)\n",
    "gen_valid = ClassifySequence(validset, wtype=wtype, batch_size=batch_size)\n",
    "\n",
    "print(len(gen_train), len(gen_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "\n",
    "output_dir = f'./output/{model_name}/{unique_id}/'\n",
    "print('output:', output_dir)\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=output_dir + \"weights-e{epoch:03d}-{acc:.4f}.hd5\", \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=True, \n",
    "                             mode='auto', \n",
    "                             save_freq='epoch',\n",
    "                             load_weights_on_restart=False)\n",
    "\n",
    "checkpoint_best = ModelCheckpoint(filepath=output_dir + \"model-best.hd5\", \n",
    "                                  monitor='val_loss', \n",
    "                                  verbose=1, \n",
    "                                  save_best_only=True, \n",
    "                                  save_weights_only=False,\n",
    "                                  mode='auto', \n",
    "                                  save_freq='epoch',\n",
    "                                  load_weights_on_restart=False)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              min_delta=0, \n",
    "                              patience=12, \n",
    "                              verbose=1, \n",
    "                              mode='auto', \n",
    "                              baseline=None, \n",
    "                              restore_best_weights=False)\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=1e-8, cooldown=0, min_lr=0)\n",
    "tensorBoard = TensorBoard(log_dir=output_dir + 'logs', histogram_freq=0, write_graph=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "csvLogger = CSVLogger(filename=output_dir + \"train_logs.csv\", separator=',', append=False)\n",
    "\n",
    "# model.fit(X_train, Y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           shuffle=True,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_valid, Y_valid),\n",
    "#           callbacks=[checkpoint, checkpoint_best, reduceLR, earlyStopping, tensorBoard, csvLogger]\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator=gen_train,\n",
    "                    steps_per_epoch=len(gen_train), \n",
    "                    epochs=epochs, \n",
    "                    verbose=1, \n",
    "                    callbacks=[checkpoint, checkpoint_best, reduceLR, earlyStopping, tensorBoard, csvLogger], \n",
    "                    validation_data=gen_valid, \n",
    "                    validation_steps=len(gen_valid), \n",
    "                    validation_freq=1, \n",
    "                    class_weight=None, \n",
    "                    max_queue_size=10, \n",
    "                    workers=1, \n",
    "                    use_multiprocessing=False, \n",
    "                    shuffle=True, \n",
    "                    initial_epoch=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
