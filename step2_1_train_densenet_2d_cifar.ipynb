{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import sys; print('Python %s on %s' % (sys.version, sys.platform))\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob, iglob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np; print('numpy', np.__version__)\n",
    "import cv2; print('opencv', cv2.__version__)\n",
    "import sklearn; print('sklearn', sklearn.__version__)\n",
    "import tensorflow as tf; print('tensorflow', tf.__version__)\n",
    "import tensorflow.keras as keras; print('keras', keras.__version__)\n",
    "\n",
    "import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.extend(['./models'])\n",
    "print('sys.path', sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gpu visible environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "# gpu allow_growth\n",
    "config.gpu_options.allow_growth = True\n",
    "keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'densenet2d'\n",
    "dataset_name = 'cifar100'\n",
    "unique_id = int(time.time())\n",
    "\n",
    "img_rows, img_cols, channels = 224, 224, 3\n",
    "num_classes = 100\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 999\n",
    "\n",
    "load_weights = False\n",
    "fine_tuning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.se_densenet import preprocess_input, SEDenseNet, SEDenseNetImageNet201\n",
    "\n",
    "base_model = SEDenseNetImageNet201(input_shape=(img_rows, img_cols, channels),\n",
    "                                  bottleneck=True,\n",
    "                                  reduction=0.5,\n",
    "                                  dropout_rate=0.2,\n",
    "                                  weight_decay=1e-4,\n",
    "                                  include_top=False,\n",
    "                                  weights=None,\n",
    "                                  input_tensor=None,\n",
    "                                  classes=num_classes,\n",
    "                                  activation='softmax')\n",
    "\n",
    "x = base_model.output\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "predictions = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# model = SEDenseNet(input_shape=None,\n",
    "#                    depth=40,\n",
    "#                    nb_dense_block=3,\n",
    "#                    growth_rate=12,\n",
    "#                    nb_filter=-1,\n",
    "#                    nb_layers_per_block=-1,\n",
    "#                    bottleneck=False,\n",
    "#                    reduction=0.0,\n",
    "#                    dropout_rate=0.0,\n",
    "#                    weight_decay=1e-4,\n",
    "#                    subsample_initial_block=False,\n",
    "#                    include_top=True,\n",
    "#                    weights=None,\n",
    "#                    input_tensor=None,\n",
    "#                    classes=10,\n",
    "#                    activation='softmax')\n",
    "\n",
    "model.summary()\n",
    "                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_name, len([l.name for l in model.layers if ('conv' in str(type(l)) or 'dense' in str(type(l)))])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10, cifar100\n",
    "\n",
    "(X_train, Y_train), (X_valid, Y_valid) = cifar100.load_data()\n",
    "\n",
    "X_train = np.array([cv2.resize(img, (img_rows, img_cols)) for img in X_train])\n",
    "X_valid = np.array([cv2.resize(img, (img_rows, img_cols)) for img in X_valid])\n",
    "\n",
    "X_train = preprocess_input(X_train.astype('float'))\n",
    "X_valid = preprocess_input(X_valid.astype('float'))\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_valid = keras.utils.to_categorical(Y_valid, num_classes)\n",
    "\n",
    "X_test = X_valid[5000:]\n",
    "Y_test = Y_valid[5000:]\n",
    "\n",
    "X_valid = X_valid[:5000]\n",
    "Y_valid = Y_valid[:5000]\n",
    "\n",
    "print('trainset:', type(X_train), X_train.shape, type(Y_train), Y_train.shape)\n",
    "print('valset:', type(X_valid), X_valid.shape, type(Y_valid), Y_valid.shape)\n",
    "print('testset:', type(X_test), X_test.shape, type(Y_test), Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
    "\n",
    "output_dir = f'./output/{model_name}/{unique_id}/'\n",
    "print('output:', output_dir)\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=output_dir + \"weights-e{epoch:03d}-{acc:.4f}.hd5\", \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=True, \n",
    "                             mode='auto', \n",
    "                             save_freq='epoch',\n",
    "                             load_weights_on_restart=False)\n",
    "\n",
    "checkpoint_best = ModelCheckpoint(filepath=output_dir + \"model-best.hd5\", \n",
    "                                  monitor='val_loss', \n",
    "                                  verbose=1, \n",
    "                                  save_best_only=True, \n",
    "                                  save_weights_only=False,\n",
    "                                  mode='auto', \n",
    "                                  save_freq='epoch',\n",
    "                                  load_weights_on_restart=False)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              min_delta=0, \n",
    "                              patience=10, \n",
    "                              verbose=1, \n",
    "                              mode='auto', \n",
    "                              baseline=None, \n",
    "                              restore_best_weights=False)\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, mode='auto', min_delta=1e-8, cooldown=0, min_lr=0)\n",
    "tensorBoard = TensorBoard(log_dir=output_dir + 'logs', histogram_freq=0, write_graph=True, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "csvLogger = CSVLogger(filename=output_dir + \"train_logs.csv\", separator=',', append=False)\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid, Y_valid),\n",
    "          callbacks=[checkpoint, checkpoint_best, reduceLR, earlyStopping, tensorBoard, csvLogger]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_trained = load_model(output_dir + \"model-best.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions_test = model_trained.predict(X_test, batch_size=batch_size, verbose=1)\n",
    "print(Y_test.shape, predictions_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "score_loss = log_loss(Y_test, predictions_test)\n",
    "score_acc = accuracy_score(np.argmax(Y_test, axis=1), np.argmax(predictions_test, axis=1))\n",
    "print('loss:', score_loss, 'accuracy:', score_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
